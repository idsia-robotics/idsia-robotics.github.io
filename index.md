---
layout: splash
title: The IDSIA Robotics Lab
header:
  image: /files/forest_header.jpg
  caption: >-
    Photo credit: Hardy Müller, courtesy [National
    Geographic Magazine](https://www.nationalgeographic.com/magazine/)
p1:
  - image_path: /files/traversability.jpg
    title: Self-supervised learning for perception and navigation
    excerpt: >-
      We develop self-supervised techniques for exploiting multimodal information while learning perception models ([paper](https://doi.org/10.1109/LRA.2022.3143565), [video](https://www.youtube.com/watch?v=fuexj03mGNo)), handle sensor uncertainty ([link](https://doi.org/10.1109/LRA.2021.3095269)) and perceive long-range obstacles ([link](https://github.com/Mirko-Nava/Learning-Long-range-Perception)).
      We also deal with quadrotor control in human proximity
      ([link](https://github.com/idsia-robotics/proximity-quadrotor-learning))
      and traversability estimation for ground robots on challenging terrain
      ([link](https://arxiv.org/abs/1709.05368)).  
      We gained widespread media attention for developing deep nets that guide a
      quadrotor [to follow a forest
      trail](http://people.idsia.ch/~giusti/forest/web/) (with the [Robotics and
      Perception Group](http://rpg.ifi.uzh.ch/) at the University of Zurich).
p2:
  - image_path: /files/boris_pointing.jpg
    title: Pointing-based human-robot interaction
    excerpt: >-
      We develop techniques based on pointing
      gestures sensed by wearable devices to identify, localize and control
      robots; possible applications span from [logistics](https://idsia-robotics.github.io/pointing/#interacting-with-a-conveyor-belt-in-virtual-reality-using-pointing-gestures) to [precision quadrotor control](https://idsia-robotics.github.io/pointing/#intuitive-3d-control-of-a-quadrotor-in-user-proximity-with-pointing-gestures) without any
      previous training.
p3:
  - image_path: /files/thymio.jpg
    title: Robotics for education
    excerpt: >-
      Using robots in education is a very important interdisciplinary field of
      research, at the crossing between educational sciences and robotics.  The
      lab is part of '*Introducing People to Research in Robotics through an
      Extended Peer Community in Southern Switzerland*': a project awarded the
      Optimus Agora Prize by the Swiss National Science Foundation
    url: >-
      http://www.snf.ch/en/researchinFocus/newsroom/Pages/news-180920-robots-in-the-classroom.aspx
    btn_label: Read More
    btn_class: btn--primary
p4:
  - image_path: /files/footbots.jpg
    title: Collaboration and planning in multi-robot systems
    excerpt: >-
      We are exploring the use of [artificial
      emotions](https://github.com/jeguzzi/artificial-emotions) for facilitating
      multi-robot coordination; in the same field, we previously developed
      [human-friendly](https://youtu.be/TYKvjofN8LE) robot navigation algorithms
      and [many other works](http://www.giannidicaro.com/robotics.html)
p5:
  - image_path: /files/industrial.jpg
    title: Applied machine learning for industrial robotics
    excerpt: >-
      The lab is active in several applied projects, deploying state-of-the-art
      deep learning techniques for sensing and process control in [electrical
      discharge
      machining](https://en.wikipedia.org/wiki/Electrical_discharge_machining)
      and large 3D-printers for complex metal objects
p6:
  - image_path: /files/nanorobotics.jpg
    title: AI-based Nanorobotics
    excerpt: >-
      The [Nanorobotics Research Group](https://idsia-robotics.github.io/nanorobotics/)
      is active in several cutting-edge projects, deploying State-of-the-Art deep learning
      techniques for perception on ultra-constrained palm-sized nano-drones.
    url: >-
      https://idsia-robotics.github.io/nanorobotics
    btn_label: Nanorobotics
    btn_class: btn--primary
published: true
---

# About

<figure style="width: 20%" class="align-right"><img src="files/idsia_logo.png"></figure>
Our lab is part of [IDSIA](http://idsia.ch) (Dalle Molle Institute for Artificial Intelligence), affiliated with both [USI](http://usi.ch) (Università della Svizzera Italiana) and [SUPSI-DTI](http://www.supsi.ch/dti/) (Scuola Universitaria Professionale della Svizzera Italiana, Dipartimento di Tecnologie Innovative).

The lab is jointy led by [Alessandro Giusti](http://www.idsia.ch/~giusti) (Professor at IDSIA USI-SUPSI), and [Luca M. Gambardella](http://www.idsia.ch/~luca) (Professor at USI); it is active in basic and applied research in autonomous mobile robotics, in close collaboration with other IDSIA researchers, namely the [Imprecise Probability Group](http://ipg.idsia.ch/) led by [Prof. Marco Zaffalon](http://people.idsia.ch/~zaffalon/) and the deep learning group led by [Prof. Jürgen Schmidhuber](http://people.idsia.ch/~juergen/).

We are part of the [National Centre of Competence in Research](https://nccr-robotics.ch) Robotics: a Swiss nationwide organization funded by the [Swiss National Science Foundation](http://www.snf.ch/en/Pages/default.aspx) pulling together top researchers from all over the country with the objective of developing new, human oriented robotic technology for improving our quality of life. In this context, we routinely collaborate with other Swiss robotics labs at [ETH Zurich](http://www.ethz.ch/), [EPFL](http://epfl.ch/) and the [University of Zurich](http://www.uzh.ch/index.html).

# Research

We work with both flying and ground mobile robots; our current research focuses on the following themes.

{% include feature_row id="p1" type="left" %}
{% include feature_row id="p2" type="left" %}
{% include feature_row id="p3" type="left" %}
{% include feature_row id="p4" type="left" %}
{% include feature_row id="p6" type="left" %}


# News

<figure style="width: 30%" class="align-right"><img src="/files/icra23.png"></figure>
## Jan 17 2023
Three new papers have just been accepted at [ICRA'23](https://www.icra2023.org/). "Dynamical System-based Imitation Learning for Visual Servoing using the Large Projection Formulation," "Deep Neural Network Architecture Search for Accurate Visual Pose Estimation aboard Nano-UAVs," [arXiv preprint](https://arxiv.org/abs/2303.01931) [demo-video](https://youtu.be/dVCScckvcg8) and "Ultra-low Power Deep Learning-based Monocular Relative Localization Onboard Nano-quadrotors" [arXiv preprint](https://arxiv.org/abs/2303.01940) [demo-video](https://youtu.be/pUGL1qu3Z1k).

<figure style="width: 30%" class="align-right"><img src="/files/nccr2022award.jpg"></figure>
## Nov 5 2022
Our 2016 paper ["A Machine Learning Approach to the Visual Perception of Forest Trails for Mobile Robots"](https://people.idsia.ch/~giusti/forest/web/) has received the "NCCR Robotics Most Impactful Paper Award".  One such award was given for each of the three grand challenges of the 12-year NCCR Robotics.

## Nov 4 2022
Our lab's research on nanodrones is covered by the swiss public TV program "Il Quotidiano".  [Link](https://www.rsi.ch/la1/programmi/informazione/il-quotidiano/), jump at minute 23:47.

## Nov 4-5 2022
Interactive demonstrations of our research on pointing-based human-robot interaction shown to hundreds of people (both robotics professionals and the general public) at the [Swiss Robotics Day 2022](https://swissroboticsday.ch/), at the Palais de Beaulieu, Lausanne.

<figure style="width: 30%" class="align-right"><img src="/files/imav2022awards.jpg"></figure>
## Sep 19 2022
The PULP team, composed of a group of researchers from our lab, Università di Bologna and TII Abu Dhabi, won the 1st Nanocopter AI challenge. 
The international competition was held in Delft on the 13th of September, and the teams were tasked with developing a palm-sized quadrotor's intelligence to enable autonomous navigation in an unknown environment cluttered with fixed and moving obstacles.
The PULP team was ranked first, beating teams from Brazil, Spain, and the Netherlands, thanks to onboard artificial intelligence capable of long collision-free flights.
They scored a remarkable 110 meters autonomous flight in 5 minutes, avoiding all moving obstacles. 
The PULP team was the first collaboration between research institutions at the forefront of nano-robotics research and innovation. The IDSIA part of the team was led by Dr. Daniele Palossi and composed by Elia Cereda (Ph.D. student), who was on the field in Delft, and the support team in Lugano: Gabriele Abbate (researcher) and Prof. Alessandro Giusti.

## Jul 21 2022
Check out our recent paper, published to the IEEE Robotics and Automation Letters with ICRA 2022 presentation: "[An Outlier Exposure Approach to Improve Visual Anomaly Detection Performance for Mobile Robots](https://ieeexplore.ieee.org/abstract/document/9834998)". Videos, datasets and code can be found on the [dedicated page](https://github.com/idsia-robotics/hazard-detection). 

## Apr 13 2022
Congratulations to [Antonio Paolillo](https://totopaolillo.github.io/) for publication of his Science Robotics paper [How to compete with robots by assessing job automation risks and resilient alternatives](https://www.science.org/doi/10.1126/scirobotics.abg5561). 

## Feb 10 2022
Check out our recent paper, published to the IEEE Robotics and Automation Letters with ICRA 2022 presentation: "[Learning Visual Localization of a Quadrotor Using its Noise as Self-Supervision](https://ieeexplore.ieee.org/document/9686072)". Videos, datasets and code can be found on the [dedicated page](https://github.com/idsia-robotics/Sound-as-Pretext). 

## Nov 29 2021
Check out our new video “[PULP-Frontnet -- Fully Onboard AI-powered Human-Drone Pose Estimation on Autonomous Flying Nano-UAVs,](https://www.youtube.com/watch?v=_kmDDYoNA3g)” available on the "[IDSIA Robotics Youtube channel.](https://www.youtube.com/user/idsiarobotics)"

## Nov 18 2021
Check out our recent paper, published to the 17th IEEE International Conference on Distributed Computing in Sensor Systems (DCOSS): "[Improving the Generalization Capability of DNNs for Ultra-low Power Autonomous Nano-UAVs.](https://ieeexplore.ieee.org/abstract/document/9600024)"

## Jun 25 2021
Check out our recent paper, published to the IEEE Robotics and Automation Letters with IROS 2021 presentation: "[Uncertainty-Aware Self-Supervised Learning of Spatial Perception Tasks](https://ieeexplore.ieee.org/document/9477010)". Videos, datasets and code can be found on the [dedicated page](https://github.com/idsia-robotics/uncertainty-aware-ssl-spatial-perception). 

## Jun 22 2021
Our recent paper “[Fully Onboard AI-powered Human-Drone Pose Estimation on Ultra-low Power Autonomous Flying Nano-UAVs,](https://ieeexplore.ieee.org/abstract/document/9462495)” has been published in the IEEE Internet of Things Journal.

## Mar 25 2021
Check out our new preprint paper on arXiv, “[Fully Onboard AI-powered Human-Drone Pose Estimation on Ultra-low Power Autonomous Flying Nano-UAVs,](https://arxiv.org/abs/2103.10873)” made in collaboration with [ETH Zürich](https://iis.ee.ethz.ch/), with the [University of Bonn](https://www.ipb.uni-bonn.de/), and the [University of Bologna.](https://dei.unibo.it/it)

## Feb 28 2021
Check out our recent open access paper, accepted to the IEEE Robotics and Automation Letters with ICRA 2021 presentation: "[State-Consistency Loss for Learning Spatial Perception Tasks from Partial Labels](https://ieeexplore.ieee.org/document/9345348/)". [more info & videos](https://github.com/idsia-robotics/state-consistency-loss){: .btn .btn--info .btn-sm}

We are also presenting at ICRA 2021: Gabriele Abbate, Boris Gromov, Luca Gambardella, Alessandro Giusti: "[Pointing at Moving Robots: Detecting Events from Wrist IMU Data](https://ieeexplore.ieee.org/document/9561387)" [more info & videos](https://github.com/idsia-robotics/pointing-detection-moving-robots){: .btn .btn--info .btn-sm}

## May 20 2020
Our highly-cited paper “[Machine-Learning Method for Quality of Transmission Prediction of Unestablished Lightpaths](https://ieeexplore.ieee.org/document/8293995)” (with [Cristina Rottondi](https://www.telematica.polito.it/member/cristina-rottondi/) and colleagues) published on the IEEE/OSA Journal of Optical Communications and Networking won the prestigious “[IEEE Communications Society Charles Kao Award](https://www.comsoc.org/about/awards/paper-awards/ieee-communications-society-charles-kao-award-best-optical-communications)”.

## Feb 10 2020
Check out our recent paper, accepted to the IEEE Robotics and Automation Letters with ICRA 2020 presentation: "[Path Planning With Local Motion Estimations](https://ieeexplore.ieee.org/abstract/document/8988152)". [code](https://github.com/idsia-robotics/pplanning-local-estimations){: .btn .btn--info .btn-sm}.  

We are presenting one additional paper at ICRA 2020: Boris Gromov, Jerome Guzzi, Luca Gambardella, and Alessandro Giusti: “Intuitive 3D Control of a Quadrotor in User Proximity with Pointing Gestures” [more info](https://idsia-robotics.github.io/pointing/#intuitive-3d-control-of-a-quadrotor-in-user-proximity-with-pointing-gestures){: .btn .btn--info .btn-sm}

## Sep 12 2019
The survey article "[The current state and future outlook of rescue robotics](https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21887)", which the lab contributed to in the context of the NCCR Robotics, is now published in the Journal of Field Robotics.

## Sep 4 2019
[Neural Rope](https://www.rsi.ch/web/archivi/shared/Tunnel-digitale-14631828.html), an interactive, public art installation by Prof. Gambardella and artist Alex Dorici, is now live and on permanent display in the Lugano Station Underpass. The ML and software infrastructure was designed and implemented by our lab. The opening was broadcast live on national TV during the [2019 Swiss Digital Day](https://www.digitaltag.swiss/).

## Mar 22 2019
Congratulations to our student Simone Mellace, who won the [Swissengineering](http://www.swissengineering-ti.ch/) [Best Thesis Award](http://www.fondazionepremio.ch/premiati/#2019) for his work on [Realtime Generation of Audible Textures Inspired by a Video Stream](https://github.com/idsia-robotics/audible-textures-from-video)!

<figure style="width: 30%" class="align-right"><img src="/files/hri2019awards.jpg"></figure>
## Mar 14 2019
Research on [pointing gestures for proximity interaction](https://idsia-robotics.github.io/pointing/) by our PhD student Boris Gromov got the best demonstration award **and** an honorable mention for the best video award at HRI 2019! Congratulations!

## Jan 26 2019

Check out our recent paper, accepted to the IEEE Robotics and Automation Letters with ICRA 2019 presentation: Mirko Nava, Jérôme Guzzi, R. Omar Chavez-Garcia, Luca M. Gambardella and Alessandro Giusti: Learning Long-range Perception using Self-Supervision from Short-Range Sensors and Odometry [more info](https://github.com/idsia-robotics/learning-long-range-perception){: .btn .btn--info .btn-sm}

We have three other papers accepted at ICRA 2019:
* Jérôme Guzzi, R. Omar Chavez-Garcia, Luca Maria Gambardella, and Alessandro Giusti: On the Impact of Uncertainty for Path Planning
* Boris Gromov, Gabriele Abbate, Luca Gambardella, and Alessandro Giusti: Proximity Human-Robot Interaction Using Pointing Gestures and a Wrist-mounted IMU [more info](https://idsia-robotics.github.io/pointing/#proximity-human-robot-interaction-using-pointing-gestures-and-a-wrist-mounted-imu){: .btn .btn--info .btn-sm}
* Dario Mantegazza, Jérôme Guzzi, Luca Maria Gambardella, and Alessandro Giusti: Vision-based Control of a Quadrotor in User Proximity: Mediated vs End-to-End Learning Approaches [more info](https://github.com/idsia-robotics/proximity-quadrotor-learning){: .btn .btn--info .btn-sm}


## Dec 22 2018

Two videos and one demo accepted at HRI 2019!

## Oct 27 2018

Two demos accepted at AAAI 2019:
* Simone Mellace, Jerome Guzzi, Alessandro Giusti and Luca Maria Gambardella: Realtime Generation of Audible Textures Inspired by a Video Stream [more info](https://github.com/idsia-robotics/audible-textures-from-video){: .btn .btn--info .btn-sm}
* Mirko Nava, Jérôme Guzzi, Ricardo Omar Chavez-Garcia, Luca Maria Gambardella and Alessandro Giusti: Learning to perceive long-range obstacles using self-supervision from short-range sensors [more info](https://github.com/idsia-robotics/learning-long-range-perception){: .btn .btn--info .btn-sm}

## Oct 8-9 2018

Our intuitive gesture-based human-drone interaction techniques were demonstrated live during [HUBWeek](https://www.swissnexboston.org/hubweek/) in Boston. [Press coverage from the Boston Globe](https://www.bostonglobe.com/business/2018/10/09/hubweek-attendees-seek-business-opportunities-and-vision-what-come/LMN7P1vkCpNFcTzwJRaivK/story.html).  [Related papers and videos](https://idsia-robotics.github.io/pointing/#video-landing-a-drone-with-pointing-gestures){: .btn .btn--info .btn-sm}

<blockquote class="instagram-media" data-instgrm-captioned data-instgrm-permalink="https://www.instagram.com/p/BorRKLeFzTO/?utm_source=ig_embed&amp;utm_medium=loading" data-instgrm-version="12" style=" background:#FFF; border:0; border-radius:3px; box-shadow:0 0 1px 0 rgba(0,0,0,0.5),0 1px 10px 0 rgba(0,0,0,0.15); margin: 1px; max-width:540px; min-width:326px; padding:0; width:99.375%; width:-webkit-calc(100% - 2px); width:calc(100% - 2px);"><div style="padding:16px;"> <a href="https://www.instagram.com/p/BorRKLeFzTO/?utm_source=ig_embed&amp;utm_medium=loading" style=" background:#FFFFFF; line-height:0; padding:0 0; text-align:center; text-decoration:none; width:100%;" target="_blank"> <div style=" display: flex; flex-direction: row; align-items: center;"> <div style="background-color: #F4F4F4; border-radius: 50%; flex-grow: 0; height: 40px; margin-right: 14px; width: 40px;"></div> <div style="display: flex; flex-direction: column; flex-grow: 1; justify-content: center;"> <div style=" background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; margin-bottom: 6px; width: 100px;"></div> <div style=" background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; width: 60px;"></div></div></div><div style="padding: 19% 0;"></div><div style="display:block; height:50px; margin:0 auto 12px; width:50px;"><svg width="50px" height="50px" viewBox="0 0 60 60" version="1.1" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g transform="translate(-511.000000, -20.000000)" fill="#000000"><g><path d="M556.869,30.41 C554.814,30.41 553.148,32.076 553.148,34.131 C553.148,36.186 554.814,37.852 556.869,37.852 C558.924,37.852 560.59,36.186 560.59,34.131 C560.59,32.076 558.924,30.41 556.869,30.41 M541,60.657 C535.114,60.657 530.342,55.887 530.342,50 C530.342,44.114 535.114,39.342 541,39.342 C546.887,39.342 551.658,44.114 551.658,50 C551.658,55.887 546.887,60.657 541,60.657 M541,33.886 C532.1,33.886 524.886,41.1 524.886,50 C524.886,58.899 532.1,66.113 541,66.113 C549.9,66.113 557.115,58.899 557.115,50 C557.115,41.1 549.9,33.886 541,33.886 M565.378,62.101 C565.244,65.022 564.756,66.606 564.346,67.663 C563.803,69.06 563.154,70.057 562.106,71.106 C561.058,72.155 560.06,72.803 558.662,73.347 C557.607,73.757 556.021,74.244 553.102,74.378 C549.944,74.521 548.997,74.552 541,74.552 C533.003,74.552 532.056,74.521 528.898,74.378 C525.979,74.244 524.393,73.757 523.338,73.347 C521.94,72.803 520.942,72.155 519.894,71.106 C518.846,70.057 518.197,69.06 517.654,67.663 C517.244,66.606 516.755,65.022 516.623,62.101 C516.479,58.943 516.448,57.996 516.448,50 C516.448,42.003 516.479,41.056 516.623,37.899 C516.755,34.978 517.244,33.391 517.654,32.338 C518.197,30.938 518.846,29.942 519.894,28.894 C520.942,27.846 521.94,27.196 523.338,26.654 C524.393,26.244 525.979,25.756 528.898,25.623 C532.057,25.479 533.004,25.448 541,25.448 C548.997,25.448 549.943,25.479 553.102,25.623 C556.021,25.756 557.607,26.244 558.662,26.654 C560.06,27.196 561.058,27.846 562.106,28.894 C563.154,29.942 563.803,30.938 564.346,32.338 C564.756,33.391 565.244,34.978 565.378,37.899 C565.522,41.056 565.552,42.003 565.552,50 C565.552,57.996 565.522,58.943 565.378,62.101 M570.82,37.631 C570.674,34.438 570.167,32.258 569.425,30.349 C568.659,28.377 567.633,26.702 565.965,25.035 C564.297,23.368 562.623,22.342 560.652,21.575 C558.743,20.834 556.562,20.326 553.369,20.18 C550.169,20.033 549.148,20 541,20 C532.853,20 531.831,20.033 528.631,20.18 C525.438,20.326 523.257,20.834 521.349,21.575 C519.376,22.342 517.703,23.368 516.035,25.035 C514.368,26.702 513.342,28.377 512.574,30.349 C511.834,32.258 511.326,34.438 511.181,37.631 C511.035,40.831 511,41.851 511,50 C511,58.147 511.035,59.17 511.181,62.369 C511.326,65.562 511.834,67.743 512.574,69.651 C513.342,71.625 514.368,73.296 516.035,74.965 C517.703,76.634 519.376,77.658 521.349,78.425 C523.257,79.167 525.438,79.673 528.631,79.82 C531.831,79.965 532.853,80.001 541,80.001 C549.148,80.001 550.169,79.965 553.369,79.82 C556.562,79.673 558.743,79.167 560.652,78.425 C562.623,77.658 564.297,76.634 565.965,74.965 C567.633,73.296 568.659,71.625 569.425,69.651 C570.167,67.743 570.674,65.562 570.82,62.369 C570.966,59.17 571,58.147 571,50 C571,41.851 570.966,40.831 570.82,37.631"></path></g></g></g></svg></div><div style="padding-top: 8px;"> <div style=" color:#3897f0; font-family:Arial,sans-serif; font-size:14px; font-style:normal; font-weight:550; line-height:18px;"> View this post on Instagram</div></div><div style="padding: 12.5% 0;"></div> <div style="display: flex; flex-direction: row; margin-bottom: 14px; align-items: center;"><div> <div style="background-color: #F4F4F4; border-radius: 50%; height: 12.5px; width: 12.5px; transform: translateX(0px) translateY(7px);"></div> <div style="background-color: #F4F4F4; height: 12.5px; transform: rotate(-45deg) translateX(3px) translateY(1px); width: 12.5px; flex-grow: 0; margin-right: 14px; margin-left: 2px;"></div> <div style="background-color: #F4F4F4; border-radius: 50%; height: 12.5px; width: 12.5px; transform: translateX(9px) translateY(-18px);"></div></div><div style="margin-left: 8px;"> <div style=" background-color: #F4F4F4; border-radius: 50%; flex-grow: 0; height: 20px; width: 20px;"></div> <div style=" width: 0; height: 0; border-top: 2px solid transparent; border-left: 6px solid #f4f4f4; border-bottom: 2px solid transparent; transform: translateX(16px) translateY(-4px) rotate(30deg)"></div></div><div style="margin-left: auto;"> <div style=" width: 0px; border-top: 8px solid #F4F4F4; border-right: 8px solid transparent; transform: translateY(16px);"></div> <div style=" background-color: #F4F4F4; flex-grow: 0; height: 12px; width: 16px; transform: translateY(-4px);"></div> <div style=" width: 0; height: 0; border-top: 8px solid #F4F4F4; border-left: 8px solid transparent; transform: translateY(-4px) translateX(8px);"></div></div></div></a> <p style=" margin:8px 0 0 0; padding:0 4px;"> <a href="https://www.instagram.com/p/BorRKLeFzTO/?utm_source=ig_embed&amp;utm_medium=loading" style=" color:#000; font-family:Arial,sans-serif; font-size:14px; font-style:normal; font-weight:normal; line-height:17px; text-decoration:none; word-wrap:break-word;" target="_blank">With its leading innovation and technology Switzerland has become the new #HomeOfDrones and you can be a part of it! Join us at @hubweek and check out Swiss drones #SwissTouch</a></p> <p style=" color:#c9c8cd; font-family:Arial,sans-serif; font-size:14px; line-height:17px; margin-bottom:0; margin-top:8px; overflow:hidden; padding:8px 0 7px; text-align:center; text-overflow:ellipsis; white-space:nowrap;">A post shared by <a href="https://www.instagram.com/swissembassyusa/?utm_source=ig_embed&amp;utm_medium=loading" style=" color:#c9c8cd; font-family:Arial,sans-serif; font-size:14px; font-style:normal; font-weight:normal; line-height:17px;" target="_blank"> Swiss Embassy in the USA</a> (@swissembassyusa) on <time style=" font-family:Arial,sans-serif; font-size:14px; line-height:17px;" datetime="2018-10-08T14:51:38+00:00">Oct 8, 2018 at 7:51am PDT</time></p></div></blockquote> <script async src="//www.instagram.com/embed.js"></script>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">A drone that can be controlled with the mere movement of an arm? <a href="https://twitter.com/IDSIARobotics?ref_src=twsrc%5Etfw">@IDSIARobotics</a> makes the fantasy come true...<a href="https://twitter.com/hashtag/HWOpenDoors?src=hash&amp;ref_src=twsrc%5Etfw">#HWOpenDoors</a> <a href="https://twitter.com/hashtag/SwissTouch?src=hash&amp;ref_src=twsrc%5Etfw">#SwissTouch</a> <a href="https://twitter.com/hashtag/DroneFrontier?src=hash&amp;ref_src=twsrc%5Etfw">#DroneFrontier</a> <a href="https://twitter.com/hashtag/Swiss4Tech?src=hash&amp;ref_src=twsrc%5Etfw">#Swiss4Tech</a> <a href="https://t.co/yNK7hlkmiX">pic.twitter.com/yNK7hlkmiX</a></p>&mdash; swissnex Boston (@swissnexBoston) <a href="https://twitter.com/swissnexBoston/status/1049367880830259206?ref_src=twsrc%5Etfw">October 8, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


## Oct 1 2018
We received an [Optimus Agora' Award](http://www.snf.ch/en/researchinFocus/newsroom/Pages/news-180920-robots-in-the-classroom.aspx) from the [Swiss National Science Foundation](http://www.snf.ch/en/Pages/default.aspx) for the project *Introducing People to Research in Robotics through an Extended Peer Community in Southern Switzerland*, a joint effort by the Educational Robotics group at SUPSI and the Laboratoire de Systèmes Robotiques at EPFL.

<figure style="width: 30%" class="align-right"><img src="/files/nzz.jpg"></figure>
## Jul 27 2018
Our research was featured in the Neue Zürcher Zeitung, one of the most prestigious daily swiss newspapers.

## Jun 29 2018
Our paper "*Robot Identification and Localization with Pointing Gestures*" was accepted at IROS 2018.  [Details](https://idsia-robotics.github.io/pointing/#robot-identification-and-localization-with-pointing-gestures){: .btn .btn--info .btn-sm}
{% include video id="VaQ3aZBf_uE" provider="youtube" %}

## Jun 27 2018
Congratulations to Jerome Guzzi, who successfully defended his PhD thesis at USI.

<figure style="width: 30%" class="align-right"><img src="/files/rsi.jpeg"></figure>
## Jus 21 2018
RSI, the italian-speaking swiss public broadcasting corporation, [covered](https://www.rsi.ch/news/oltre-la-news/Svizzera-Eldorado-dei-droni-10598922.html) our drone research and filmed their journalists interacting with our robots.

## Mar 24 2018
Our paper "*A model of artificial emotions for behavior modulation and implicit coordination in multi-robot systems*" was accepted at GECCO 2018 in the Swarm Intelligence Track (acceptance rate 22%). [Details](https://github.com/jeguzzi/artificial-emotions){: .btn .btn--info .btn-sm}

<figure style="width: 30%" class="align-right"><img src="/files/premio_swissengineering.jpg"></figure>
## Mar 15 2018
Congratulations to our BSc Students Stefano Toniolo and Denis Broggini. Stefano won the [Swissengineering](http://www.swissengineering-ti.ch/) [Talent Ticino Prize](http://www.fondazionepremio.ch/premiati/#2018) for his work on [self-supervised learning for obstacle detection](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16374).  Denis won the best presentation award for his work on ML for poinging gesture detection using wearable IMUs.

## Feb 5 2018
Our self-supervised learning techniques demonstrated to the public during the AAAI 2018 demo session ([link](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16374))

## Jan 26 2018
CNN journalists from [Connect the World](https://edition.cnn.com/shows/connect-the-world) filmed our robots in action.

## Jan 15 2018
Our paper on *Learning Ground Traversability from Simulations* accepted for the IEEE Robotics and Automation Letters ([arxiv](https://arxiv.org/abs/1709.05368))

## Dec 23 2017
Our video "landing a drone with pointing gestures" was accepted at HRI 2018.  [Details](https://idsia-robotics.github.io/pointing/#video-landing-a-drone-with-pointing-gestures){: .btn .btn--info}
{% include video id="jpG8Jsmth2Y" provider="youtube" %}

## Dec 12 2017
With several other NCCR Robotics laboratories we have been collaborating on an integrative demo project targeted at rescue missions.  The resulting video, which was recorded during the live demo held in Lausanne in Nov 2017, features some of our research about [human-robot interaction](https://idsia-robotics.github.io/pointing/#video-landing-a-drone-with-pointing-gestures) and machine learning for [traversability estimation](https://arxiv.org/abs/1709.05368).
{% include video id="y0uUGiPL8Vo" provider="youtube" %}


# Work with us

[Contact us](mailto:alessandrog@idsia.ch) if you are interested in a position in our lab as a Research Engineer, PhD student, or Post-doc researcher.

# Sponsors

- [Swiss National Science Foundation](http://www.snf.ch/en/Pages/default.aspx)
- [National Centre of Competence in Research (NCCR) Robotics](https://nccr-robotics.ch)
- [Innosuisse](https://www.innosuisse.ch/inno/de/home.html)
- The [Eurostars-Eureka](https://www.eurekanetwork.org/) programme of the EU
- [NVidia](https://developer.nvidia.com/academic_gpu_seeding) GPU Grants
